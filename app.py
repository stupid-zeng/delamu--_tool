import streamlit as st
import pandas as pd
import io

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½® (å¿…é¡»æ”¾åœ¨ç¬¬ä¸€è¡Œ)
# ==========================================
st.set_page_config(page_title="å¤–ååº“å­˜è°ƒæ‹¨ç³»ç»Ÿ", layout="wide", page_icon="ğŸ­")

# ==========================================
# 2. æ ¸å¿ƒéšç§ä¿æŠ¤ä»£ç  (æ ¸å¼¹çº§éšè—)
#    è¿™æ®µä»£ç èƒ½æœ‰æ•ˆé˜²æ­¢è®¿å®¢çœ‹åˆ° GitHub å…¥å£å’Œå³ä¸‹è§’å·¥å…·æ 
# ==========================================
hide_st_style = """
    <style>
    /* 1. éšè—é¡¶éƒ¨çš„æ±‰å ¡èœå• */
    #MainMenu {visibility: hidden; display: none !important;}
    
    /* 2. éšè—é¡µè„š "Made with Streamlit" */
    footer {visibility: hidden; display: none !important;}
    
    /* 3. éšè—é¡¶éƒ¨çš„å½©è‰²è£…é¥°æ¡å’Œæ•´ä¸ªå¤´éƒ¨åŒºåŸŸ */
    header {visibility: hidden; display: none !important;}
    [data-testid="stHeader"] {visibility: hidden; display: none !important;}
    
    /* 4. æš´åŠ›éšè—å³ä¸‹è§’çš„ Streamlit å·¥å…·æ /å¤´åƒ */
    /* é’ˆå¯¹æ–°ç‰ˆ Streamlit çš„ Toolbar */
    [data-testid="stToolbar"] {
        visibility: hidden !important;
        display: none !important;
        height: 0px !important;
    }
    
    /* é’ˆå¯¹æ—§ç‰ˆç»“æ„çš„éšè— */
    .stApp > header {
        visibility: hidden !important;
        display: none !important;
    }
    
    /* éšè—çŠ¶æ€ç»„ä»¶ (Running...) */
    div[data-testid="stStatusWidget"] {
        visibility: hidden !important;
        display: none !important;
    }
    
    /* éšè—å¤´åƒæ¡† */
    [data-testid="stDecoration"] {
        visibility: hidden !important;
        display: none !important;
    }

    /* 5. è°ƒæ•´ä¸»åŒºåŸŸä¸Šè¾¹è·ï¼Œé˜²æ­¢é¡¶éƒ¨ç•™ç™½è¿‡å¤§ */
    .block-container {
        padding-top: 1rem !important;
    }
    </style>
    """
st.markdown(hide_st_style, unsafe_allow_html=True)

# ==========================================
# 3. ä¸»ç¨‹åºæ ‡é¢˜ä¸é€»è¾‘ (ä¿æŒä¸å˜)
# ==========================================
st.title("ğŸ­ å¤–å/å¤©æºåº“å­˜ -> ç›´æ¥è°ƒæ‹¨å•ç”Ÿæˆå™¨")
st.markdown("##### ğŸš€ åŠŸèƒ½ï¼šè‡ªåŠ¨æ‰«æè¡¨å¤´ | ä¼˜å…ˆåŒ¹é…å¯ç”¨åº“å­˜ | æŒ‰åº“åŒºæ‹†åˆ†å¯¼å‡º")

# --- è¾…åŠ©å‡½æ•°ï¼šè‡ªåŠ¨å¯»æ‰¾è¡¨å¤´ ---
def load_and_find_header(file_obj):
    """
    è‡ªåŠ¨æ‰«æå‰10è¡Œï¼Œæ‰¾åˆ°åŒ…å« 'SKU' çš„é‚£ä¸€è¡Œä½œä¸ºè¡¨å¤´
    è§£å†³ Excel ç¬¬ä¸€è¡Œæ˜¯è¯´æ˜æ–‡å­—çš„é—®é¢˜
    """
    try:
        file_obj.seek(0)
        # 1. è¯»å–æ–‡ä»¶
        if file_obj.name.endswith('.csv'):
            try:
                df_raw = pd.read_csv(file_obj, header=None, encoding='utf-8-sig')
            except:
                file_obj.seek(0)
                df_raw = pd.read_csv(file_obj, header=None, encoding='gbk')
        else:
            df_raw = pd.read_excel(file_obj, header=None)
        
        # 2. æ‰«æå‰ 10 è¡Œ
        header_row_index = -1
        for i in range(min(10, len(df_raw))):
            row_values = [str(v).strip().upper() for v in df_raw.iloc[i].values]
            if 'SKU' in row_values:
                header_row_index = i
                break
        
        if header_row_index == -1:
            return None, "âŒ æ‰«æå¤±è´¥ï¼šå‰10è¡Œæœªæ‰¾åˆ°åŒ…å«'SKU'çš„è¡Œï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚"

        # 3. è®¾ç½®è¡¨å¤´
        df_final = df_raw.iloc[header_row_index+1:].copy()
        df_final.columns = df_raw.iloc[header_row_index].values
        df_final.reset_index(drop=True, inplace=True)
        
        return df_final, f"âœ… å·²å®šä½è¡¨å¤´åœ¨ç¬¬ {header_row_index+1} è¡Œ"

    except Exception as e:
        return None, f"âŒ æ–‡ä»¶è¯»å–ä¸¥é‡é”™è¯¯: {e}"

# --- æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½é€‰åˆ— ---
def smart_select_columns(df):
    """
    è§£å†³åˆ—åé‡å¤é—®é¢˜ï¼šä»å¤šä¸ªåŒååˆ—ä¸­ï¼ŒæŒ‘é€‰æœ€åˆé€‚çš„é‚£ä¸€åˆ—
    """
    # 1. æ¸…æ´—åˆ—åï¼šè½¬å­—ç¬¦ä¸²ã€å»ç©ºæ ¼
    df.columns = [str(c).strip() for c in df.columns]
    all_cols = list(df.columns)
    
    selected_cols = {}
    
    # --- A. å¯»æ‰¾ FNSKU (ä¼˜å…ˆåŒ¹é… FNSKU, fnsku) ---
    fnsku_candidates = [c for c in all_cols if 'FNSKU' in c.upper()]
    if fnsku_candidates:
        selected_cols['FNSKU'] = fnsku_candidates[0]
    else:
        # å¦‚æœæ²¡æ‰¾åˆ° FNSKUï¼Œè¿”å›ç©ºï¼Œä¸è¦æŠ¥é”™ï¼Œåé¢æµç¨‹ä¼šå¤„ç†
        return None, f"âŒ æœªæ‰¾åˆ° FNSKU åˆ—ã€‚ç°æœ‰åˆ—åï¼š{all_cols}"

    # --- B. å¯»æ‰¾ SKU (ä¸èƒ½åŒ…å« FNSKU) ---
    sku_candidates = [c for c in all_cols if 'SKU' in c.upper() and 'FNSKU' not in c.upper()]
    if sku_candidates:
        sku_candidates.sort(key=len)
        selected_cols['SKU'] = sku_candidates[0]
    else:
        return None, "âŒ æœªæ‰¾åˆ° SKU åˆ—ã€‚"

    # --- C. å¯»æ‰¾ ä»“åº“ ---
    wh_candidates = [c for c in all_cols if 'ä»“åº“' in c]
    if wh_candidates:
        selected_cols['Warehouse'] = wh_candidates[0]
    else:
        return None, "âŒ æœªæ‰¾åˆ° ä»“åº“ åˆ—ã€‚"

    # --- D. å¯»æ‰¾ åº“å­˜ (æœ€å…³é”®!!!) ---
    # ä¼˜å…ˆçº§ï¼šåŒ…å«'å¯ç”¨' > åŒ…å«'åº“å­˜' (ä¸”ä¸æ˜¯åº“å­˜ä¸»ä½“)
    stock_candidates_priority = [c for c in all_cols if 'å¯ç”¨' in c]
    if stock_candidates_priority:
        selected_cols['Stock'] = stock_candidates_priority[0]
    else:
        stock_others = [c for c in all_cols if 'åº“å­˜' in c and 'ä¸»ä½“' not in c and 'å¿½ç•¥' not in c]
        if stock_others:
            selected_cols['Stock'] = stock_others[0]
        else:
             return None, "âŒ æœªæ‰¾åˆ° åº“å­˜/å¯ç”¨æ•°é‡ åˆ—ã€‚"

    # --- E. å¯»æ‰¾ åº“åŒº ---
    zone_candidates = [c for c in all_cols if 'åº“åŒº' in c and 'æ ‡è®°' not in c]
    if zone_candidates:
        selected_cols['Zone'] = zone_candidates[0]
    else:
        selected_cols['Zone'] = None 

    # --- æ„å»ºå¹²å‡€çš„ DataFrame ---
    df_clean = pd.DataFrame()
    df_clean['SKU'] = df[selected_cols['SKU']]
    df_clean['FNSKU'] = df[selected_cols['FNSKU']]
    df_clean['Warehouse'] = df[selected_cols['Warehouse']]
    df_clean['Stock'] = df[selected_cols['Stock']]
    
    if selected_cols['Zone']:
        df_clean['Zone'] = df[selected_cols['Zone']]
    else:
        df_clean['Zone'] = '' # å¦‚æœæ²¡æœ‰åº“åŒºåˆ—ï¼Œç»™ç©ºå€¼

    # å†æ¬¡å»é‡åˆ—åï¼Œé˜²æ­¢æ„å¤–
    df_clean = df_clean.loc[:, ~df_clean.columns.duplicated()]

    return df_clean, f"åˆ—æ˜ å°„æŠ¥å‘Šï¼šSKU[{selected_cols['SKU']}] | åº“å­˜[{selected_cols['Stock']}]"

# --- ä¸»å¤„ç†é€»è¾‘ ---
def process_data(df_demand, inv_file, plan_file=None):
    logs = []
    results = []

    # 1. è¯»å–åŸå§‹åº“å­˜
    df_inv_raw, msg = load_and_find_header(inv_file)
    if df_inv_raw is None: return None, msg, None

    # 2. æ™ºèƒ½é€‰åˆ— (è§£å†³é‡å¤åˆ—é—®é¢˜)
    df_inv, col_msg = smart_select_columns(df_inv_raw)
    if df_inv is None: return None, col_msg, None
    
    # 3. æ•°æ®æ¸…æ´— (å¼ºè½¬ç±»å‹é˜²æ­¢æŠ¥é”™)
    df_inv['SKU'] = df_inv['SKU'].astype(str).str.strip()
    df_inv['FNSKU'] = df_inv['FNSKU'].astype(str).str.strip()
    df_inv['Warehouse'] = df_inv['Warehouse'].astype(str).str.strip()
    df_inv['Zone'] = df_inv['Zone'].astype(str).str.strip()
    df_inv['Stock'] = pd.to_numeric(df_inv['Stock'], errors='coerce').fillna(0)

    # 4. ç­›é€‰å¤–å/å¤©æº
    filter_mask = df_inv['Warehouse'].str.contains("å¤–å|å¤©æº", na=False)
    df_inv_target = df_inv[filter_mask].copy()
    
    debug_info = {
        "col_msg": col_msg,
        "target_count": len(df_inv_target),
        "clean_head": df_inv.head(3)
    }

    if df_inv_target.empty:
        return None, "âš ï¸ ç­›é€‰åæ•°æ®ä¸ºç©ºï¼è¯·æ£€æŸ¥â€œä»“åº“â€åˆ—æ˜¯å¦åŒ…å«â€œå¤–åâ€æˆ–â€œå¤©æºâ€ã€‚", debug_info

    # 5. æ‰£å‡è®¡åˆ’ (å¦‚æœä¸Šä¼ äº†)
    if plan_file is not None:
        df_plan_raw, _ = load_and_find_header(plan_file)
        if df_plan_raw is not None:
            # ç®€å•çš„è®¡åˆ’è¡¨æ¸…æ´—
            df_plan_raw.columns = [str(c).strip() for c in df_plan_raw.columns]
            p_map = {}
            for c in df_plan_raw.columns:
                if 'FNSKU' in c.upper(): p_map[c] = 'FNSKU'
                elif 'éœ€æ±‚' in c or 'QTY' in c.upper(): p_map[c] = 'PlanQty'
                elif 'SKU' in c.upper(): p_map[c] = 'SKU'
            df_plan_raw.rename(columns=p_map, inplace=True)
            
            # å»é‡åˆ—
            df_plan_raw = df_plan_raw.loc[:, ~df_plan_raw.columns.duplicated()]

            if 'SKU' in df_plan_raw and 'PlanQty' in df_plan_raw:
                df_plan_raw['SKU'] = df_plan_raw['SKU'].astype(str).str.strip()
                if 'FNSKU' in df_plan_raw:
                     df_plan_raw['FNSKU'] = df_plan_raw['FNSKU'].astype(str).str.strip()
                else:
                     df_plan_raw['FNSKU'] = ''
                
                df_plan_raw['PlanQty'] = pd.to_numeric(df_plan_raw['PlanQty'], errors='coerce').fillna(0)
                
                plan_dict = df_plan_raw.groupby(['SKU', 'FNSKU'])['PlanQty'].sum().to_dict()
                
                for idx, row in df_inv_target.iterrows():
                    key = (row['SKU'], row['FNSKU'])
                    if key in plan_dict and plan_dict[key] > 0:
                        deduct = min(row['Stock'], plan_dict[key])
                        df_inv_target.at[idx, 'Stock'] -= deduct
                        plan_dict[key] -= deduct

    # 6. åŒ¹é…é€»è¾‘
    # è¿™é‡Œçš„å…³é”®æ˜¯æŒ‰åº“å­˜ä»å¤§åˆ°å°æ’åºï¼Œä¼˜å…ˆæ¶ˆè€—åº“å­˜å¤šçš„ï¼Œæˆ–ä¸ºè¡¥ä½åšå‡†å¤‡
    df_inv_target.sort_values(by='Stock', ascending=False, inplace=True)

    df_demand['SKU'] = df_demand['SKU'].astype(str).str.strip()
    if 'FnSKU' in df_demand.columns: df_demand['FNSKU'] = df_demand['FnSKU'].astype(str).str.strip()
    elif 'FNSKU' in df_demand.columns: df_demand['FNSKU'] = df_demand['FNSKU'].astype(str).str.strip()
    df_demand['è®¢å•éœ€æ±‚'] = pd.to_numeric(df_demand['è®¢å•éœ€æ±‚'], errors='coerce').fillna(0)

    for idx, row in df_demand.iterrows():
        sku = row['SKU']
        target_fnsku = row['FNSKU']
        qty_needed = row['è®¢å•éœ€æ±‚']
        
        if sku == 'nan' or qty_needed <= 0: continue

        # --- A. ç›®æ ‡ FNSKU åŒ¹é… ---
        matches = df_inv_target[
            (df_inv_target['SKU'] == sku) & 
            (df_inv_target['FNSKU'] == target_fnsku)
        ]
        
        for _, inv_row in matches.iterrows():
            if qty_needed <= 0: break
            avail = inv_row['Stock']
            if avail <= 0: continue 
            
            take = min(qty_needed, avail)
            results.append({
                'SKU': sku, 'FNSKU': target_fnsku, 'è°ƒæ‹¨æ•°é‡': take,
                'è°ƒå‡ºä»“åº“': inv_row['Warehouse'], 'è°ƒå‡ºåº“åŒº': inv_row['Zone'], 'å¤‡æ³¨': 'ç›®æ ‡åŒ¹é…'
            })
            qty_needed -= take
            
        # --- B. è¡¥ä½åŒ¹é… (æ‰¾åŒSKUä½†ä¸åŒFNSKUçš„) ---
        if qty_needed > 0:
            subs = df_inv_target[
                (df_inv_target['SKU'] == sku) & 
                (df_inv_target['FNSKU'] != target_fnsku)
            ]
            for _, inv_row in subs.iterrows():
                if qty_needed <= 0: break
                avail = inv_row['Stock']
                if avail <= 0: continue
                
                take = min(qty_needed, avail)
                results.append({
                    'SKU': sku, 'FNSKU': inv_row['FNSKU'], # æ³¨æ„ï¼šè¿™é‡Œå¡«çš„æ˜¯å®é™…å‘è´§çš„ FNSKU
                    'è°ƒæ‹¨æ•°é‡': take,
                    'è°ƒå‡ºä»“åº“': inv_row['Warehouse'], 'è°ƒå‡ºåº“åŒº': inv_row['Zone'], 'å¤‡æ³¨': 'è‡ªåŠ¨è¡¥ä½'
                })
                qty_needed -= take
        
        if qty_needed > 0:
            logs.append(f"SKU {sku} (FnSKU: {target_fnsku}) ç¼ºè´§: {qty_needed}")

    if not results:
        return None, "âŒ è®¡ç®—å®Œæˆï¼Œä½†æœªç”Ÿæˆä»»ä½•è°ƒæ‹¨å•ã€‚\nåŸå› å¯èƒ½æ˜¯ï¼š1.åº“å­˜ä¸è¶³ï¼›2.éœ€æ±‚SKUä¸åº“å­˜SKUä¸åŒ¹é…ã€‚", debug_info
    
    # 7. æ ¼å¼åŒ–è¾“å‡º (æŒ‰æ‚¨çš„å›¾ç‰‡è¦æ±‚å®šåˆ¶)
    df_res = pd.DataFrame(results)
    
    # å›ºå®šå­—æ®µå¡«å……
    df_res['è°ƒæ‹¨ç±»å‹'] = 'ç»„ç»‡å†…è°ƒæ‹¨'
    df_res['è°ƒå…¥ä»“åº“'] = 'DLMä¾›åº”é“¾äºšé©¬é€Šæ·±åœ³ä»“-SZ'
    df_res['è°ƒå…¥åº“åŒº'] = 'æˆå“-å­˜å‚¨1åŒº'
    
    # åº“åŒºå…œåº•ï¼šå¦‚æœä¸ºç©ºï¼Œç”¨è°ƒå‡ºä»“åº“æš‚ä»£
    df_res['è°ƒå‡ºåº“åŒº'] = df_res.apply(lambda x: x['è°ƒå‡ºåº“åŒº'] if x['è°ƒå‡ºåº“åŒº'] and str(x['è°ƒå‡ºåº“åŒº'])!='nan' else x['è°ƒå‡ºä»“åº“'], axis=1)

    # æœ€ç»ˆå­—æ®µé¡ºåº
    final_cols = ['è°ƒæ‹¨ç±»å‹', 'è°ƒå‡ºä»“åº“', 'è°ƒå…¥ä»“åº“', 'SKU', 'FNSKU', 'è°ƒå‡ºåº“åŒº', 'è°ƒå…¥åº“åŒº', 'è°ƒæ‹¨æ•°é‡', 'å¤‡æ³¨']
    for c in final_cols:
        if c not in df_res.columns: df_res[c] = ''
            
    return df_res[final_cols], logs, debug_info

# --- ç•Œé¢å¸ƒå±€ ---
col_in, col_up = st.columns([35, 65])

with col_in:
    st.subheader("1. éœ€æ±‚æ•°æ®è¾“å…¥")
    st.caption("è¯·ä»Excelå¤åˆ¶ç²˜è´´ï¼šSKU | FnSKU | è®¢å•éœ€æ±‚")
    default = pd.DataFrame(columns=["SKU", "FnSKU", "è®¢å•éœ€æ±‚"])
    edited_df = st.data_editor(default, num_rows="dynamic", height=450)

with col_up:
    st.subheader("2. ä¸Šä¼ æ–‡ä»¶")
    st.info("ğŸ’¡ ç³»ç»Ÿä¼šè‡ªåŠ¨æ‰«æè¡¨å¤´ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®è¡Œå·ã€‚")
    inv_file = st.file_uploader("ğŸ“‚ A. ä¸Šä¼ ã€Šåœ¨åº“åº“å­˜ã€‹ (å¿…å¡«)", type=['xlsx', 'xls', 'csv'])
    plan_file = st.file_uploader("ğŸ“‚ B. ä¸Šä¼ ã€Šæè´§è®¡åˆ’ã€‹ (é€‰å¡«ï¼Œç”¨äºæ‰£å‡)", type=['xlsx', 'xls', 'csv'])
    
    st.divider()
    run = st.button("ğŸš€ ç”Ÿæˆè°ƒæ‹¨å• (æŒ‰åº“åŒºæ‹†åˆ†)", type="primary", use_container_width=True)

if run:
    if inv_file and not edited_df.empty:
        with st.spinner("æ­£åœ¨æ™ºèƒ½åˆ†ææ•°æ®..."):
            try:
                res, msgs, debug = process_data(edited_df, inv_file, plan_file)
                
                # --- ğŸ•µï¸â€â™‚ï¸ ä¾¦æ¢æ¨¡å¼ï¼šå¦‚æœå‡ºé—®é¢˜å¯ä»¥ç‚¹å¼€çœ‹ ---
                if debug:
                    with st.expander("ğŸ•µï¸â€â™‚ï¸ è°ƒè¯•ä¿¡æ¯ (ç‚¹å‡»å±•å¼€æŸ¥çœ‹è¯»å–è¯¦æƒ…)", expanded=False):
                        st.text(debug['col_msg'])
                        st.write(f"æœ‰æ•ˆå¤–ååº“å­˜è¡Œæ•°ï¼š{debug['target_count']}")
                        st.write("æ¸…æ´—åæ•°æ®å‰3è¡Œé¢„è§ˆï¼š")
                        st.dataframe(debug['clean_head'])

                if res is not None:
                    if msgs:
                        with st.expander(f"âš ï¸ ç¼ºè´§æ—¥å¿— ({len(msgs)}æ¡)"):
                            st.write(msgs)
                    
                    st.success(f"âœ… å¤„ç†æˆåŠŸï¼å…±ç”Ÿæˆ {len(res)} æ¡æŒ‡ä»¤ã€‚")
                    st.markdown("---")
                    
                    # === æŒ‰åº“åŒºæ‹†åˆ†å¯¼å‡º ===
                    unique_zones = res['è°ƒå‡ºåº“åŒº'].unique()
                    
                    # ä½¿ç”¨å¤šåˆ—å¸ƒå±€
                    cols = st.columns(3) 
                    for i, zone in enumerate(unique_zones):
                        sub_df = res[res['è°ƒå‡ºåº“åŒº'] == zone]
                        
                        # ç”Ÿæˆ Excel
                        buf = io.BytesIO()
                        with pd.ExcelWriter(buf, engine='xlsxwriter') as writer:
                            sub_df.to_excel(writer, index=False)
                        
                        safe_name = str(zone).replace('/', '_').replace('\\', '_')
                        
                        with cols[i % 3]:
                            st.info(f"ğŸ“¦ **{safe_name}** ({len(sub_df)}è¡Œ)")
                            st.download_button(
                                label=f"ğŸ“¥ ä¸‹è½½ {safe_name}.xlsx",
                                data=buf.getvalue(),
                                file_name=f"{safe_name}.xlsx",
                                mime="application/vnd.ms-excel",
                                key=f"dl_{i}"
                            )
                else:
                    st.error(msgs)
            except ImportError:
                st.error("âŒ ç¯å¢ƒé”™è¯¯ï¼šç¼ºå°‘ xlsxwriter åº“ã€‚è¯·åœ¨ requirements.txt ä¸­æ·»åŠ  xlsxwriterã€‚")
            except Exception as e:
                st.error(f"è¿è¡Œå‡ºé”™: {e}")
    else:
        st.warning("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥éœ€æ±‚ï¼Œå¹¶åœ¨å³ä¾§ä¸Šä¼ åº“å­˜æ–‡ä»¶ã€‚")
