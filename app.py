import streamlit as st
import pandas as pd
import numpy as np
import io

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="ç›´æ¥è°ƒæ‹¨å•ç”Ÿæˆå™¨", layout="wide")

st.title("ğŸ“¦ è‡ªåŠ¨åŒ–ç›´æ¥è°ƒæ‹¨å•ç”Ÿæˆå™¨")
st.markdown("### é€»è¾‘ï¼šåº“å­˜æ‰£å‡ -> FNSKUåŒ¹é… -> è‡ªåŠ¨æ‹†è¡Œè¡¥ä½")

# --- ä¾§è¾¹æ ï¼šå‚æ•°è®¾ç½® ---
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°è®¾ç½®")
    header_row = st.number_input("Excelè¡¨å¤´æ‰€åœ¨è¡Œ (é»˜è®¤ç¬¬2è¡Œè¯·è¾“å…¥1)", min_value=0, value=1, help="Pythonæ˜¯ä»0å¼€å§‹è®¡æ•°çš„ï¼Œå¦‚æœè¡¨å¤´åœ¨ç¬¬2è¡Œï¼Œè¿™é‡Œå¡«1")
    st.info("è¯´æ˜ï¼š\n1. è¯·ç¡®ä¿åº“å­˜è¡¨ä¸­åŒ…å«ã€å¯ç”¨åº“å­˜ã€ä»“åº“åç§°ã€FnSKUã€åº“åŒºã€‘å­—æ®µã€‚\n2. æ”¯æŒç›´æ¥ç²˜è´´éœ€æ±‚æ•°æ®ã€‚")

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---
def process_data(df_demand, df_inv, df_plan=None):
    logs = [] # ç”¨äºè®°å½•å¤„ç†æ—¥å¿—
    results = []

    # 1. å­—æ®µæ ‡å‡†åŒ– (å»é™¤ç©ºæ ¼)
    df_inv.columns = [str(c).strip() for c in df_inv.columns]
    
    # 2. å­—æ®µæ˜ å°„ (å…¼å®¹æ€§å¤„ç†)
    # å°è¯•è‡ªåŠ¨å¯»æ‰¾å¯¹åº”çš„åˆ—åï¼Œé˜²æ­¢Excelåˆ—åå¾®å°å˜åŠ¨
    col_map = {
        'å¯ç”¨åº“å­˜': 'Stock', 'ä»“åº“åç§°': 'Warehouse', 'FnSKU': 'FNSKU', 'åº“åŒº': 'Zone',
        'SKU': 'SKU'
    }
    # ç®€å•çš„åˆ—åæ£€æŸ¥
    for key, val in col_map.items():
        # å¦‚æœæ‰¾ä¸åˆ°æ ‡å‡†åï¼Œå°è¯•æ‰¾åŒ…å«è¯¥åçš„åˆ—
        if key not in df_inv.columns:
            found = False
            for c in df_inv.columns:
                if key in c:
                    df_inv.rename(columns={c: val}, inplace=True)
                    found = True
                    break
            if not found and key != 'åº“åŒº': # åº“åŒºéå¿…é¡»ï¼Œå…¶ä»–å¿…é¡»
                return None, f"é”™è¯¯ï¼šåº“å­˜è¡¨ä¸­æ‰¾ä¸åˆ°ã€{key}ã€‘åˆ—ï¼Œè¯·æ£€æŸ¥è¡¨å¤´ã€‚"
        else:
            df_inv.rename(columns={key: val}, inplace=True)

    # 3. æ•°æ®æ¸…æ´—
    df_inv['Stock'] = pd.to_numeric(df_inv['Stock'], errors='coerce').fillna(0)
    
    # 4. ç­›é€‰å¤–å/å¤©æºä»“åº“
    def is_target_wh(name):
        if pd.isna(name): return False
        return ("å¤–å" in str(name)) or ("å¤©æº" in str(name))
    
    df_inv_target = df_inv[df_inv['Warehouse'].apply(is_target_wh)].copy()
    
    # 5. æ‰£å‡æè´§è®¡åˆ’ (å¦‚æœæœ‰)
    if df_plan is not None:
        # è¿™é‡Œå‡è®¾è®¡åˆ’è¡¨ä¹Ÿæœ‰ SKU, FNSKU, è®¡åˆ’æ•°
        # å®é™…é€»è¾‘éœ€è¦æ ¹æ®æ‚¨å…·ä½“çš„è®¡åˆ’è¡¨ç»“æ„æ¥å†™ï¼Œè¿™é‡Œåšä¸ªé¢„ç•™æ¡†æ¶
        pass 
    
    # æŒ‰åº“å­˜é™åºæ’åºï¼ˆä¸ºäº†ä¼˜å…ˆæ‹¿åº“å­˜æœ€å¤šçš„å…¶ä»–FNSKUè¡¥ä½ï¼‰
    df_inv_target.sort_values(by='Stock', ascending=False, inplace=True)

    # 6. å¾ªç¯å¤„ç†æ¯ä¸€è¡Œéœ€æ±‚
    for idx, row in df_demand.iterrows():
        sku = row['SKU']
        target_fnsku = row['FNSKU']
        qty_needed = row['éœ€æ±‚æ•°']
        country = row['å›½å®¶'] # ä¿ç•™å›½å®¶ä¿¡æ¯

        if pd.isna(sku) or qty_needed <= 0: continue
        
        # ä¿®æ­£ï¼šéœ€æ±‚æ•°è½¬ä¸ºfloat/int
        try:
            qty_needed = float(qty_needed)
        except:
            continue

        # --- é˜¶æ®µ1ï¼šæ‰¾ç›®æ ‡FNSKU ---
        target_rows = df_inv_target[(df_inv_target['SKU'] == sku) & (df_inv_target['FNSKU'] == target_fnsku)]
        
        for _, stock_row in target_rows.iterrows():
            if qty_needed <= 0: break
            
            avail = stock_row['Stock']
            can_take = min(qty_needed, avail)
            
            if can_take > 0:
                results.append({
                    'å›½å®¶': country,
                    'è°ƒå‡ºä»“åº“': stock_row['Warehouse'],
                    'è°ƒå…¥ä»“åº“': 'DLMä¾›åº”é“¾äºšé©¬é€Šæ·±åœ³ä»“-SZ',
                    'SKU': sku,
                    'FNSKU': target_fnsku, # åŸé…
                    'è°ƒæ‹¨æ•°é‡': can_take,
                    'åº“åŒº': stock_row.get('Zone', ''), # é˜²æ­¢æ²¡æœ‰åº“åŒºåˆ—
                    'å¤‡æ³¨': 'ç›®æ ‡åŒ¹é…'
                })
                qty_needed -= can_take
                
        # --- é˜¶æ®µ2ï¼šè¡¥ä½ (æ‰¾åŒSKUå…¶ä»–FNSKU) ---
        if qty_needed > 0:
            other_rows = df_inv_target[(df_inv_target['SKU'] == sku) & (df_inv_target['FNSKU'] != target_fnsku)]
            
            for _, stock_row in other_rows.iterrows():
                if qty_needed <= 0: break
                
                avail = stock_row['Stock']
                can_take = min(qty_needed, avail)
                
                if can_take > 0:
                    results.append({
                        'å›½å®¶': country,
                        'è°ƒå‡ºä»“åº“': stock_row['Warehouse'],
                        'è°ƒå…¥ä»“åº“': 'DLMä¾›åº”é“¾äºšé©¬é€Šæ·±åœ³ä»“-SZ',
                        'SKU': sku,
                        'FNSKU': stock_row['FNSKU'], # æ›¿è¡¥ FNSKU
                        'è°ƒæ‹¨æ•°é‡': can_take,
                        'åº“åŒº': stock_row.get('Zone', ''),
                        'å¤‡æ³¨': 'è‡ªåŠ¨è¡¥ä½'
                    })
                    qty_needed -= can_take
        
        # å¦‚æœè¿˜æ˜¯ä¸å¤Ÿ
        if qty_needed > 0:
            logs.append(f"âš ï¸ è­¦å‘Šï¼šSKU {sku} (ç›®æ ‡FNSKU {target_fnsku}) æ€»åº“å­˜ä¸è¶³ï¼Œä»ç¼ºè´§ {qty_needed}")

    if not results:
        return None, "æ²¡æœ‰ç”Ÿæˆä»»ä½•è°ƒæ‹¨æ•°æ®ï¼Œè¯·æ£€æŸ¥åº“å­˜æ˜¯å¦å……è¶³æˆ–SKUæ˜¯å¦åŒ¹é…ã€‚"
    
    return pd.DataFrame(results), logs

# --- ç•Œé¢å¸ƒå±€ ---

col1, col2 = st.columns([1, 1])

# --- åŒºåŸŸ 1: éœ€æ±‚è¾“å…¥ (æ”¯æŒç²˜è´´) ---
with col1:
    st.subheader("1. è¾“å…¥/ç²˜è´´ è°ƒæ‹¨éœ€æ±‚")
    st.caption("è¯·ç›´æ¥ä»Excelå¤åˆ¶æ•°æ®ç²˜è´´åˆ°ä¸‹æ–¹è¡¨æ ¼ä¸­ï¼ˆç‚¹å‡»é¦–è¡Œé¦–åˆ—ç²˜è´´ï¼‰")
    
    # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„DataFrameæ¨¡æ¿
    template_data = pd.DataFrame(columns=["å›½å®¶", "SKU", "FNSKU", "éœ€æ±‚æ•°"])
    # é¢„ç•™10è¡Œç©ºè¡Œæ–¹ä¾¿ç²˜è´´
    # template_data = pd.concat([template_data, pd.DataFrame([['']]*10, columns=template_data.columns)], ignore_index=True)

    edited_df = st.data_editor(
        template_data,
        num_rows="dynamic", # å…è®¸åŠ¨æ€æ·»åŠ è¡Œ
        use_container_width=True,
        height=300
    )

# --- åŒºåŸŸ 2: æ–‡ä»¶ä¸Šä¼  (æ”¯æŒExcel) ---
with col2:
    st.subheader("2. ä¸Šä¼ æ•°æ®æºæ–‡ä»¶")
    
    # åœ¨åº“åº“å­˜ä¸Šä¼ 
    inv_file = st.file_uploader("ä¸Šä¼ ã€Šåœ¨åº“åº“å­˜ã€‹è¡¨", type=['xlsx', 'xls', 'csv'])
    
    # æè´§è®¡åˆ’ä¸Šä¼ 
    plan_file = st.file_uploader("ä¸Šä¼ ã€Šç¾å›½æè´§è®¡åˆ’ã€‹è¡¨ (å¯é€‰)", type=['xlsx', 'xls', 'csv'])

# --- æ‰§è¡ŒæŒ‰é’® ---
st.divider()
if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆç›´æ¥è°ƒæ‹¨å•", type="primary"):
    if edited_df.dropna(how='all').empty:
        st.error("è¯·åœ¨å·¦ä¾§è¾“å…¥éœ€æ±‚æ•°æ®ï¼")
    elif not inv_file:
        st.error("è¯·ä¸Šä¼ åœ¨åº“åº“å­˜æ–‡ä»¶ï¼")
    else:
        with st.spinner("æ­£åœ¨è®¡ç®—å¹¶æ‹†åˆ†åº“åŒº..."):
            try:
                # 1. è¯»å–åº“å­˜æ–‡ä»¶ (æ”¯æŒ Excel)
                if inv_file.name.endswith('.csv'):
                    df_inv = pd.read_csv(inv_file, header=header_row, encoding='utf-8-sig') # å°è¯•å¸¸ç”¨ç¼–ç 
                else:
                    df_inv = pd.read_excel(inv_file, header=header_row)

                # 2. è¯»å–è®¡åˆ’æ–‡ä»¶ (æš‚ç•™ç©ºï¼Œé€»è¾‘åŒä¸Š)
                df_plan = None
                if plan_file:
                    if plan_file.name.endswith('.csv'):
                        df_plan = pd.read_csv(plan_file, header=header_row)
                    else:
                        df_plan = pd.read_excel(plan_file, header=header_row)

                # 3. è¿è¡Œå¤„ç†
                result_df, logs = process_data(edited_df, df_inv, df_plan)

                if isinstance(result_df, pd.DataFrame):
                    st.success(f"æˆåŠŸç”Ÿæˆï¼å…± {len(result_df)} æ¡è°ƒæ‹¨æŒ‡ä»¤")
                    
                    # æ˜¾ç¤ºæ—¥å¿—
                    if logs:
                        with st.expander("æŸ¥çœ‹å¤„ç†æ—¥å¿—/è­¦å‘Š"):
                            for log in logs:
                                st.write(log)

                    # --- ç»“æœå±•ç¤ºä¸ä¸‹è½½ ---
                    st.dataframe(result_df.head())
                    
                    # å‡†å¤‡ä¸‹è½½æ–‡ä»¶ï¼šæ€»è¡¨
                    buffer_master = io.BytesIO()
                    with pd.ExcelWriter(buffer_master, engine='xlsxwriter') as writer:
                        result_df.to_excel(writer, index=False, sheet_name='æ€»è¡¨')
                    
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å®Œæ•´æ±‡æ€»è¡¨ (.xlsx)",
                        data=buffer_master.getvalue(),
                        file_name="ç›´æ¥è°ƒæ‹¨å•_æ±‡æ€».xlsx",
                        mime="application/vnd.ms-excel"
                    )

                    # å‡†å¤‡ä¸‹è½½æ–‡ä»¶ï¼šåˆ†ä»“è¡¨
                    st.markdown("### ğŸ˜ï¸ å„åº“åŒºç‹¬ç«‹æ–‡ä»¶ä¸‹è½½")
                    unique_whs = result_df['è°ƒå‡ºä»“åº“'].unique()
                    
                    # ä½¿ç”¨ columns å¸ƒå±€ä¸‹è½½æŒ‰é’®
                    cols = st.columns(len(unique_whs))
                    for i, wh in enumerate(unique_whs):
                        sub_df = result_df[result_df['è°ƒå‡ºä»“åº“'] == wh]
                        
                        buffer_sub = io.BytesIO()
                        with pd.ExcelWriter(buffer_sub, engine='xlsxwriter') as writer:
                            sub_df.to_excel(writer, index=False, sheet_name='Sheet1')
                        
                        safe_name = str(wh).replace('/', '_')
                        cols[i].download_button(
                            label=f"ğŸ“¥ {safe_name} ({len(sub_df)}è¡Œ)",
                            data=buffer_sub.getvalue(),
                            file_name=f"ç›´æ¥è°ƒæ‹¨å•_{safe_name}.xlsx",
                            mime="application/vnd.ms-excel"
                        )
                else:
                    st.error(logs) # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯

            except Exception as e:
                st.error(f"å‘ç”Ÿç¨‹åºé”™è¯¯: {e}")
                st.exception(e)